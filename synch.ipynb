{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synch\n",
    "\n",
    "Synch is a music recommendation engine built on measured signal rather than popularity, trends, or social noise.\n",
    "\n",
    "Tracks are represented as vectors in a high-dimensional acoustic and semantic space, and recommendations are generated by proximity in that space rather than by human behavior.\n",
    "\n",
    "Music is treated as a physical system: **sound → numbers → similarity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset construction\n",
    "\n",
    "More than 5,000 tracks were collected.\n",
    "\n",
    "The raw files were heterogeneous: some had complete metadata, others were partially tagged, and some were incorrect.\n",
    "\n",
    "Because downstream modeling is only as good as the input, a manual data integrity phase was introduced before any automation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata verification\n",
    "\n",
    "All tracks were inspected and corrected using Mp3tag with MusicBrainz lookups.\n",
    "\n",
    "This ensured that artist names, titles, albums, release years, and genres were standardized and trustworthy.\n",
    "\n",
    "After verification, metadata was exported into a structured CSV to serve as the base layer.\n",
    "\n",
    "The dataset schema was defined as:\n",
    "\n",
    "- title\n",
    "- track_number\n",
    "- disc_number\n",
    "- duration_seconds\n",
    "- album\n",
    "- album_artist\n",
    "- contributing_artists\n",
    "- genre_tagged\n",
    "- year\n",
    "- file_path\n",
    "\n",
    "One critical field was still missing: a stable track identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deterministic track identity\n",
    "\n",
    "Since no global ID existed across the source files, a deterministic track_id was constructed from multiple attributes of each track.\n",
    "\n",
    "The goal was not cryptographic uniqueness but collision-resistant identity for a dataset on the order of 10,000 tracks.\n",
    "\n",
    "The ID is generated from:\n",
    "\n",
    "- title\n",
    "- track number\n",
    "- disc number\n",
    "- duration\n",
    "- album\n",
    "- album artist\n",
    "- contributing artists\n",
    "- genre\n",
    "- year\n",
    "\n",
    "These fields are normalized, reduced to stable characters, and combined into a reproducible identifier.\n",
    "\n",
    "This makes:\n",
    "\n",
    "- identical files always produce the same ID\n",
    "- small metadata errors detectable\n",
    "- joins between metadata and audio features reliable\n",
    "\n",
    "Unicode normalization and tag cleanup are applied before ID generation to avoid hidden collisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata extraction pipeline\n",
    "\n",
    "A custom extraction script walks the audio library, reads tags using Mutagen, cleans and normalizes them, and exports a CSV.\n",
    "\n",
    "Key processing steps include:\n",
    "\n",
    "- Unicode normalization and encoding repair (ftfy, unicodedata)\n",
    "- Artist and genre tokenization and deduplication\n",
    "- Year parsing\n",
    "- Track and disc number normalization\n",
    "- Deterministic track_id generation\n",
    "\n",
    "The output is a clean, stable metadata spine for the entire project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample (metadata.csv)\n",
    "\n",
    "| track_id | title | album | album_artist | contributing_artists | genre_tagged | year |\n",
    "|----------|-------|-------|--------------|---------------------|--------------|------|\n",
    "| b11119pgze10 | Broken | Plastic Beach | Gorillaz | Gorillaz | Electronic;Hip-Hop;Pop | 2010 |\n",
    "| s6117pgle10 | Superfast Jellyfish | Plastic Beach | Gorillaz | Gorillaz; Gruff Rhys; De La Soul | Electronic;Hip-Hop;Pop | 2010 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio feature extraction\n",
    "\n",
    "Once the metadata layer was stable, the next phase converted sound into numbers.\n",
    "\n",
    "All audio files are high-quality lossless or high-bitrate formats to ensure numerical accuracy.\n",
    "\n",
    "Feature extraction is performed using Essentia, a professional-grade audio analysis library used in music information retrieval research.\n",
    "\n",
    "Because Essentia is Linux-native, the environment runs inside WSL for compatibility and reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-level acoustic features\n",
    "\n",
    "The lowlevel.py pipeline computes frame-based and track-level statistics from each audio file.\n",
    "\n",
    "For each track:\n",
    "\n",
    "1. The waveform is loaded and converted to mono.\n",
    "2. The signal is split into overlapping frames.\n",
    "3. Each frame is transformed into the frequency domain.\n",
    "4. Core spectral features are computed.\n",
    "5. Statistics are aggregated over the entire track.\n",
    "\n",
    "Extracted features include:\n",
    "\n",
    "| Feature | Meaning |\n",
    "|---------|----------|\n",
    "| MFCCs | Timbre and texture |\n",
    "| Spectral centroid | Brightness |\n",
    "| Spectral flatness | Tonality vs noise |\n",
    "| Spectral flux | Temporal change |\n",
    "| RMS | Loudness |\n",
    "\n",
    "These are reduced to means and standard deviations to give one vector per track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample (lowlevel.csv)\n",
    "\n",
    "| track_id | mfcc_1_mean | spectral_centroid_mean | spectral_flatness_mean | rms_mean |\n",
    "|----------|-------------|------------------------|------------------------|----------|\n",
    "| b11119pgze10 | -533.7 | 0.132 | 0.164 | 0.321 |\n",
    "| s6117pgle10 | -556.6 | 0.180 | 0.291 | 0.321 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next stage introduces high-level features using Essentia's ML models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
